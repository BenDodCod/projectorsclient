# Enhanced Projector Control Application - CI Pipeline
# Runs on every push and pull request to main branch
# Version: 2.0.0 - Week 5-6 DevOps Enhancement

name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION_DEFAULT: "3.11"
  COVERAGE_THRESHOLD: 90

jobs:
  # ===========================================================================
  # Stage 1: Code Quality (Matrix: Python 3.10, 3.11, 3.12)
  # ===========================================================================
  code-quality:
    name: Code Quality (Python ${{ matrix.python-version }})
    runs-on: windows-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black flake8 pylint mypy isort
          pip install -r requirements.txt
          pip install PyQt6-stubs types-jsonschema

      - name: Check formatting with Black
        run: black --check --diff src/ tests/

      - name: Check import sorting with isort
        run: isort --check-only --diff src/ tests/

      - name: Lint with flake8
        run: flake8 src/ tests/ --count --show-source --statistics --max-line-length=120

      - name: Lint with Pylint
        run: pylint src/ --exit-zero --output-format=colorized
        continue-on-error: true

      - name: Type check with MyPy
        run: mypy src/ --ignore-missing-imports
        continue-on-error: true

  # ===========================================================================
  # Stage 2: Unit Tests (Matrix: Python 3.10, 3.11, 3.12)
  # ===========================================================================
  unit-tests:
    name: Unit Tests (Python ${{ matrix.python-version }})
    runs-on: windows-latest
    needs: code-quality
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run unit tests with coverage
        run: |
          pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --cov-fail-under=${{ env.COVERAGE_THRESHOLD }}

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-py${{ matrix.python-version }}
          path: |
            coverage.xml
            htmlcov/

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.11'
        with:
          files: coverage.xml
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  # ===========================================================================
  # Stage 3: Integration Tests
  # ===========================================================================
  integration-tests:
    name: Integration Tests
    runs-on: windows-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run integration tests
        run: |
          pytest tests/integration/ -v --cov=src --cov-append --cov-report=xml

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: coverage.xml

  # ===========================================================================
  # Stage 4: Security Scanning
  # ===========================================================================
  security-scan:
    name: Security Scan
    runs-on: windows-latest
    needs: code-quality
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: pip

      - name: Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety pip-audit semgrep

      - name: Run Bandit security scan
        run: |
          bandit -r src/ -f json -o bandit-results.json -ll
          bandit -r src/ -f txt --exit-zero

      - name: Check dependencies with Safety
        run: safety check -r requirements.txt --full-report || true
        continue-on-error: true

      - name: Audit dependencies with pip-audit
        run: pip-audit -r requirements.txt || true
        continue-on-error: true

      - name: Run Semgrep static analysis
        run: |
          semgrep --config=auto src/ --json -o semgrep-results.json || true
        continue-on-error: true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-results.json
            semgrep-results.json

  # ===========================================================================
  # Stage 5: UI Tests
  # ===========================================================================
  ui-tests:
    name: UI Tests
    runs-on: windows-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install pytest-qt pytest-xvfb

      - name: Run UI tests
        run: |
          pytest tests/ui/ -v --cov=src/ui --cov-report=xml -x
        env:
          QT_QPA_PLATFORM: offscreen

      - name: Upload UI test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ui-test-results
          path: coverage.xml

  # ===========================================================================
  # Stage 6: Build Executable
  # ===========================================================================
  build:
    name: Build Executable
    runs-on: windows-latest
    needs: [unit-tests, security-scan, integration-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pyinstaller

      - name: Verify package structure
        run: |
          python -c "import src; print(f'Package version: {src.__version__}')"

      - name: Build executable
        run: |
          pyinstaller projector_control.spec --noconfirm --clean
        continue-on-error: true

      - name: Verify build output
        run: |
          if (Test-Path "dist/ProjectorControl.exe") {
            Write-Host "Build successful: dist/ProjectorControl.exe"
            $size = (Get-Item "dist/ProjectorControl.exe").Length / 1MB
            Write-Host "Executable size: $([math]::Round($size, 2)) MB"
          } else {
            Write-Host "Build not yet available - main.py implementation pending"
          }
        shell: pwsh

      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: ProjectorControl-${{ github.sha }}
          path: dist/ProjectorControl.exe
          if-no-files-found: ignore

  # ===========================================================================
  # Stage 7: Release (on tag)
  # ===========================================================================
  release:
    name: Create Release
    runs-on: windows-latest
    needs: build
    if: startsWith(github.ref, 'refs/tags/v')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: ProjectorControl-${{ github.sha }}
          path: dist/

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/ProjectorControl.exe
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================================================
  # Summary Job
  # ===========================================================================
  ci-complete:
    name: CI Complete
    runs-on: windows-latest
    needs: [code-quality, unit-tests, security-scan, integration-tests, build]
    if: always()
    steps:
      - name: Check job results
        run: |
          $results = @{
            "code-quality" = "${{ needs.code-quality.result }}"
            "unit-tests" = "${{ needs.unit-tests.result }}"
            "security-scan" = "${{ needs.security-scan.result }}"
            "integration-tests" = "${{ needs.integration-tests.result }}"
            "build" = "${{ needs.build.result }}"
          }

          $failed = $false
          foreach ($job in $results.Keys) {
            $status = $results[$job]
            if ($status -eq "failure") {
              Write-Host "FAILED: $job"
              $failed = $true
            } elseif ($status -eq "success") {
              Write-Host "PASSED: $job"
            } else {
              Write-Host "SKIPPED/OTHER: $job ($status)"
            }
          }

          if ($failed) {
            Write-Host "`nCI Pipeline FAILED"
            exit 1
          }
          Write-Host "`nCI Pipeline PASSED - All stages successful"
        shell: pwsh

      - name: Post summary
        run: |
          echo "## CI Pipeline Summary" >> $env:GITHUB_STEP_SUMMARY
          echo "" >> $env:GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $env:GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $env:GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ needs.code-quality.result }} |" >> $env:GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result }} |" >> $env:GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security-scan.result }} |" >> $env:GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result }} |" >> $env:GITHUB_STEP_SUMMARY
          echo "| Build | ${{ needs.build.result }} |" >> $env:GITHUB_STEP_SUMMARY
        shell: pwsh
